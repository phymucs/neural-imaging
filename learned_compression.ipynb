{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tqdm\n",
    "import io\n",
    "import imageio\n",
    "\n",
    "from collections import deque\n",
    "from skimage.transform import resize, rescale\n",
    "# from sewar.full_ref import msssim, ssim\n",
    "from skimage.measure import compare_ssim as ssim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Own libraries and modules\n",
    "from helpers import loading, plotting, utils, summaries, tf_helpers\n",
    "from models import compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = {\n",
    "    'n_epochs': 5000,\n",
    "    'batch_size': 40,\n",
    "    'patch_size': 128\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_size = 128\n",
    "n_latent = 1024\n",
    "n_latent_bytes = 0.5\n",
    "\n",
    "bitmap_size = patch_size * patch_size * 3\n",
    "compression_rate = bitmap_size / (n_latent_bytes * n_latent)\n",
    "compression_bpp = 8 * n_latent * n_latent_bytes / patch_size / patch_size\n",
    "\n",
    "print('Bitmap size: {:,d} bytes'.format(bitmap_size))\n",
    "print('Latent size: {:,}-D'.format(n_latent))\n",
    "print('Latent repr: {:,} bytes'.format(n_latent * n_latent_bytes))\n",
    "print('Compression rate: 1:{}'.format(compression_rate))\n",
    "print('Compression Fi  : {:.2f} bpp'.format(compression_bpp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IPDataset:\n",
    "    \n",
    "    def __init__(self, data_directory, randomize=False, load='xy', val_patch_size=128, val_n_patches=2, n_images=120, v_images=30):\n",
    "        self.files = {}\n",
    "        self.files['training'], self.files['validation'] = loading.discover_files(data_directory, randomize=randomize, n_images=n_images, v_images=v_images)\n",
    "                \n",
    "        self.data = {\n",
    "            'training': loading.load_images(self.files['training'], data_directory=data_directory, load=load),\n",
    "            'validation': loading.load_patches(self.files['validation'], data_directory=data_directory, patch_size=val_patch_size // 2, n_patches=val_n_patches, load=load, discard_flat=True)\n",
    "        }\n",
    "        \n",
    "        if 'x' in self.data['training']:\n",
    "            self.H, self.W = self.data['training']['x'].shape[1:3]\n",
    "        else:\n",
    "            self.H, self.W = self.data['training']['y'].shape[1:3]\n",
    "            \n",
    "        print('Loaded dataset with {}x{} images'.format(self.W, self.H))\n",
    "        \n",
    "    def __getitem__(self, key):\n",
    "        if key in ['training', 'validation']:\n",
    "            return self.data[key]\n",
    "        else:\n",
    "            return super().__getitem__(key)\n",
    "        \n",
    "    def next_training_batch(self, batch_id, batch_size, patch_size, discard_flat=True):\n",
    "        batch_x = np.zeros((batch_size, patch_size, patch_size, 3), dtype=np.float32)\n",
    "        for b in range(batch_size):\n",
    "            \n",
    "            found = False            \n",
    "            panic_counter = 5\n",
    "            \n",
    "            while not found:\n",
    "                xx = np.random.randint(0, self.W - patch_size)\n",
    "                yy = np.random.randint(0, self.H - patch_size)\n",
    "\n",
    "                patch = self.data['training']['y'][batch_id * batch_size + b, yy:yy + patch_size, xx:xx + patch_size, :].astype(np.float) / (2**8 - 1)\n",
    "\n",
    "                # Check if the found patch is acceptable: eliminate empty patches\n",
    "                if discard_flat:\n",
    "                    patch_variance = np.var(patch)\n",
    "                    if patch_variance < 1e-2:\n",
    "                        panic_counter -= 1\n",
    "                        found = False if panic_counter > 0 else True\n",
    "                    elif patch_variance < 0.02:\n",
    "                        found = np.random.uniform() > 0.5\n",
    "                    else:\n",
    "                        found = True\n",
    "                else:\n",
    "                    found = True\n",
    "            \n",
    "            batch_x[b, :, :, :] = patch\n",
    "        return batch_x\n",
    "\n",
    "    def next_validation_batch(self, batch_id, batch_size, output_patch_size=None):\n",
    "        patch_size = self.data['validation']['y'].shape[1]\n",
    "        batch_x = np.zeros((batch_size, patch_size, patch_size, 3), dtype=np.float32)\n",
    "        for b in range(batch_size):\n",
    "            batch_x[b, :, :, :] = self.data['validation']['y'][batch_id * batch_size + b].astype(np.float)\n",
    "        if output_patch_size is None or output_patch_size == patch_size:\n",
    "            return batch_x\n",
    "        else:\n",
    "            return batch_x[:, :output_patch_size, :output_patch_size, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "# camera_name = \"Nikon D90\"\n",
    "# data_directory = os.path.join('./data/raw/nip_training_data/', camera_name)\n",
    "data_directory = os.path.join('./data/raw/compression_data/')\n",
    "\n",
    "# data = IPDataset(data_directory, n_images=120, v_images=30, load='y')\n",
    "# data = IPDataset(data_directory, n_images=16000, v_images=800, load='y', val_patch_size=training['patch_size'])\n",
    "data = IPDataset(data_directory, n_images=4000, v_images=200, load='y', val_patch_size=training['patch_size'])\n",
    "\n",
    "for dataset in ['training', 'validation']:\n",
    "    print('{} : {}'.format(dataset, data[dataset]['y'].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show sample batch from the database\n",
    "if 'batch_id' not in globals():\n",
    "    batch_id = 0\n",
    "    n_batches = data['training']['y'].shape[0] // training['batch_size']\n",
    "    \n",
    "batch_id = (batch_id + 1) % n_batches\n",
    "\n",
    "print('Batch id: {} ({})'.format(batch_id, training['batch_size']))\n",
    "\n",
    "batch_x = data.next_training_batch(batch_id, training['batch_size'], training['patch_size'])\n",
    "fig = plotting.imsc(batch_x[:8], ncols=8, figwidth=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Deep Compression Network Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoencoderDCN(compression.DCN):\n",
    "    \n",
    "    def construct_model(self, *, n_filters=8, n_fscale=2, n_latent=0, kernel=5, n_layers=3, r_layers=0, dropout=True, rounding='soft', \n",
    "                        is_training=True, train_codebook=False, latent_bpf=8, scale_latent=True, activation=tf.nn.leaky_relu, entropy_weight=None):\n",
    "        \n",
    "        # Sanity checks:\n",
    "        if n_layers < 1:\n",
    "            raise ValueError('n_layers needs to be > 0!')\n",
    "        \n",
    "        self.n_layers = n_layers\n",
    "        self.r_layers = r_layers\n",
    "        self.n_latent = n_latent\n",
    "        self.n_filters = n_filters\n",
    "        self.n_fscale = n_fscale\n",
    "        self.kernel = kernel\n",
    "        self.is_training = is_training\n",
    "        self.train_codebook = train_codebook\n",
    "        self.scale_latent = scale_latent\n",
    "        self.entropy_weight = entropy_weight\n",
    "        self.latent_bpf = latent_bpf\n",
    "        self.uses_bottleneck = n_latent > 0\n",
    "        \n",
    "        latent_activation = None\n",
    "        last_activation = None\n",
    "\n",
    "        print('Building Deep Compression Network')\n",
    "\n",
    "        net = self.x\n",
    "        print('in size: {}'.format(net.shape))\n",
    "\n",
    "        # Encoder ---------------------------------------------------------------------------------------------------------------\n",
    "        \n",
    "        # Add convolutional layers\n",
    "        n_filters = self.n_filters\n",
    "\n",
    "        for r in range(self.n_layers):\n",
    "            current_activation = activation if (n_latent > 0 or (n_latent == 0 and r < self.n_layers - 1)) else latent_activation\n",
    "            net = tf.contrib.layers.conv2d(net, n_filters, self.kernel, stride=2, scope='dcn{}/encoder/conv_{}'.format(self.label, r), activation_fn=current_activation)\n",
    "            print('conv size: {} + {}'.format(net.shape, current_activation.__name__ if current_activation is not None else None))\n",
    "            if r != self.n_layers - 1:\n",
    "                n_filters *= self.n_fscale\n",
    "            \n",
    "        # Add residual blocks\n",
    "        for r in range(self.r_layers):\n",
    "            resnet = tf.contrib.layers.conv2d(tf.nn.leaky_relu(net, name='dcn{}/encoder/res_{}/lrelu'.format(self.label, r)),    n_filters, 3, stride=1, activation_fn=activation, scope='dcn{}/encoder/res_{}/conv_{}'.format(self.label, r, 0))\n",
    "            resnet = tf.contrib.layers.conv2d(resnet, n_filters, 3, stride=1, activation_fn=None,       scope='dcn{}/encoder/res_{}/conv_{}'.format(self.label, r, 1))\n",
    "            net = tf.add(net, resnet, name='dcn{}/encoder/res_{}/sum'.format(self.label, r))\n",
    "            print('residual block: {}'.format(net.shape))        \n",
    "\n",
    "        # Latent representation -----------------------------------------------------------------------------------------------------------\n",
    "            \n",
    "        # Add batch norm to normalize the latent representation\n",
    "        if is_training is not None:            \n",
    "            net = tf.contrib.layers.batch_norm(net, scale=True, is_training=is_training, scope='dcn{}/encoder/bn_{}'.format(self.label, 0))\n",
    "            print('batch norm: {} train:{}'.format(net.shape, is_training))\n",
    "        \n",
    "        # Flatten and get latent representation\n",
    "        z_spatial = int(self.patch_size / (2**self.n_layers))\n",
    "        z_features = int(self.n_filters * (self.n_fscale**(self.n_layers-1)))\n",
    "        self.latent_shape = [-1, z_spatial, z_spatial, z_features]\n",
    "\n",
    "        # If a smaller linear bottleneck is specified explicitly - add dense layers to make the projection\n",
    "        if n_latent is not None and n_latent != 0:\n",
    "            flat = tf.contrib.layers.flatten(net, scope='dcn{}/encoder/flatten_{}'.format(self.label, 0))\n",
    "            print('flatten size: {}'.format(flat.shape))\n",
    "            \n",
    "            if n_latent > 0:\n",
    "                flat = tf.contrib.layers.fully_connected(flat, self.n_latent, activation_fn=latent_activation, scope='dcn{}/encoder/dense_{}'.format(self.label, 0))\n",
    "                latent = tf.identity(flat, name='dcn{}/latent'.format(self.label))\n",
    "                print('dense size: {}'.format(flat.shape))\n",
    "            else:\n",
    "                latent = tf.identity(flat, name='dcn{}/latent'.format(self.label))                \n",
    "        else:\n",
    "            latent = tf.identity(net, name='dcn{}/latent'.format(self.label))\n",
    "        \n",
    "        # Learn a scaling factor for the latent features to encourage greater values (facilitates quantization)\n",
    "        if self.scale_latent:\n",
    "            alphas = tf.get_variable('dcn{}/latent_scaling'.format(dcn.label), shape=(), dtype=tf.float32, initializer=tf.ones_initializer)\n",
    "            latent = tf.multiply(alphas, latent, name='dcn{}/latent_scaled'.format(self.label))            \n",
    "\n",
    "        # Quantize the latent representation and remember tensors before and after the process\n",
    "        self.latent_pre = latent\n",
    "        latent = tf_helpers.quantization(latent, 'dcn{}/quantization'.format(self.label), 'latent_quantized', rounding)                        \n",
    "        self.latent_post = latent\n",
    "        self.n_latent = int(np.prod(latent.shape[1:]))\n",
    "        print('latent size: {} + quant:{}'.format(latent.shape, rounding))\n",
    "        \n",
    "        if n_latent > 0:\n",
    "            inet = tf.contrib.layers.fully_connected(latent, int(np.prod(self.latent_shape[1:])), activation_fn=activation, scope='dcn{}/decoder/dense_{}'.format(self.label, 0))\n",
    "            print('dense size: {} + {}'.format(inet.shape, activation))\n",
    "        else:\n",
    "            inet = latent\n",
    "\n",
    "        # Add dropout\n",
    "        if dropout > 0:\n",
    "            self.dropout = tf.placeholder(tf.float32, name='dcn{}/droprate'.format(self.label), shape=())\n",
    "            inet = tf.contrib.layers.dropout(inet, keep_prob=self.dropout, scope='dcn{}/dropout'.format(self.label))\n",
    "            print('dropout size: {}'.format(net.shape))\n",
    "            \n",
    "        # Decoder ---------------------------------------------------------------------------------------------------------------\n",
    "        \n",
    "        # Just in case - make sure we have a multidimensional tensor before we start the convolutions\n",
    "        inet = tf.reshape(inet, self.latent_shape, name='dcn{}/decoder/reshape_{}'.format(self.label, 0))\n",
    "        print('reshape size: {}'.format(inet.shape))\n",
    "\n",
    "        # Add residual blocks\n",
    "        for r in range(self.r_layers):\n",
    "            resnet = tf.contrib.layers.conv2d(tf.nn.leaky_relu(inet, name='dcn{}/encoder/res_{}/lrelu'.format(self.label, r)),   n_filters, 3, stride=1, activation_fn=activation, scope='dcn{}/decoder/res_{}/conv_{}'.format(self.label, r, 0))\n",
    "            resnet = tf.contrib.layers.conv2d(resnet, n_filters, 3, stride=1, activation_fn=None,       scope='dcn{}/decoder/res_{}/conv_{}'.format(self.label, r, 1))\n",
    "            inet = tf.add(inet, resnet, name='dcn{}/decoder/res_{}/sum'.format(self.label, r))\n",
    "            print('residual block: {}'.format(net.shape))                \n",
    "        \n",
    "        # Transposed convolutions\n",
    "        for r in range(self.n_layers):            \n",
    "            current_activation = last_activation if r == self.n_layers - 1 else activation\n",
    "            inet = tf.contrib.layers.conv2d(inet, 2 * n_filters, self.kernel, stride=1, scope='dcn{}/decoder/tconv_{}'.format(self.label, r), activation_fn=current_activation)\n",
    "            print('conv size: {} + {}'.format(inet.shape, current_activation.__name__ if current_activation is not None else None))\n",
    "            inet = tf.depth_to_space(inet, 2, name='dcn{}/decoder/d2s_{}'.format(self.label, r))\n",
    "#             inet = tf.contrib.layers.conv2d_transpose(inet, 3 if r == self.n_layers - 1 else n_filters, self.kernel, stride=2,  activation_fn=current_activation, scope='dcn{}/tconv_{}'.format(self.label, r))\n",
    "            print('d2s size: {} + {}'.format(inet.shape, None))\n",
    "            n_filters = n_filters // self.n_fscale\n",
    "\n",
    "        inet = tf.contrib.layers.conv2d(inet, 3, self.kernel, stride=1, activation_fn=last_activation, scope='dcn{}/decoder/tconv_out'.format(self.label))\n",
    "        print('conv->out size: {} + {}'.format(inet.shape, last_activation))\n",
    "        y = tf.identity(inet, name='y')\n",
    "            \n",
    "        self.y = y\n",
    "        self.latent = latent\n",
    "    \n",
    "    def short_name(self):\n",
    "        parameter_summary = []\n",
    "        \n",
    "        if hasattr(self, 'latent_shape'):\n",
    "            parameter_summary.append('x'.join(str(x) for x in self.latent_shape[1:]))\n",
    "\n",
    "        layer_summary = []\n",
    "        if hasattr(self, 'n_layers'):\n",
    "            layer_summary.append('{:d}C'.format(self.n_layers))\n",
    "        if hasattr(self, 'res_layers'):\n",
    "            layer_summary.append('{:d}R'.format(self.res_layers))\n",
    "        if self.uses_bottleneck:\n",
    "            layer_summary.append('F')\n",
    "        if hasattr(self, 'dropout'):\n",
    "            layer_summary.append('+D')\n",
    "        if hasattr(self, 'is_training') and self.is_training is not None:\n",
    "            layer_summary.append('+BN')\n",
    "            \n",
    "        parameter_summary.append(''.join(layer_summary))                        \n",
    "        parameter_summary.append('Q+{}bpf'.format(self.latent_bpf) if self.train_codebook else 'Q-{}bpf'.format(self.latent_bpf))\n",
    "        parameter_summary.append('S+' if self.scale_latent else 'S-')\n",
    "        if self.entropy_weight is not None:\n",
    "            parameter_summary.append('H+{:.2f}'.format(self.entropy_weight))\n",
    "\n",
    "        return '{}/{}'.format(super().short_name(), '-'.join(parameter_summary))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwitterDCN(compression.DCN):\n",
    "    \"\"\"\n",
    "    Auto-encoder architecture described in:\n",
    "    [1] L. Theis, W. Shi, A. Cunningham, and F. Huszár, “Lossy Image Compression with Compressive Autoencoders,” Mar. 2017.\n",
    "    \"\"\"\n",
    "    \n",
    "    def construct_model(self):\n",
    "        \n",
    "        activation = tf.nn.leaky_relu\n",
    "        latent_activation = tf.nn.tanh\n",
    "        last_activation = tf.nn.sigmoid\n",
    "        \n",
    "        self.n_layers = 9\n",
    "        self.n_latent = \n",
    "\n",
    "        print('Building Deep Compression Network with d-latent={}'.format(self.n_latent))\n",
    "        \n",
    "        \n",
    "        with tf.name_scope('dcn{}/normalization'.format(self.label)):\n",
    "            net = 2 * (self.x - 0.5)\n",
    "            print('net size: {}'.format(net.shape))\n",
    "\n",
    "        # Convolutions        \n",
    "#         n_filters = self.n_filters\n",
    "        \n",
    "        net = tf.contrib.layers.conv2d(net,  64, 5, stride=2, activation_fn=activation, scope='dcn{}/encoder/conv_{}'.format(self.label, 0))\n",
    "        net = tf.contrib.layers.conv2d(net, 128, 5, stride=2, activation_fn=None, scope='dcn{}/encoder/conv_{}'.format(self.label, 1))\n",
    "        \n",
    "        resnet = tf.contrib.layers.conv2d(tf.nn.leaky_relu(net, name='dcn{}/encoder/conv_{}/lrelu'.format(self.label, 1)), 128, 3, stride=1, activation_fn=activation, scope='dcn{}/encoder/conv_{}'.format(self.label, 2))\n",
    "        resnet = tf.contrib.layers.conv2d(resnet, 128, 3, stride=1, activation_fn=None, scope='dcn{}/encoder/conv_{}'.format(self.label, 3))\n",
    "        net = tf.add(net, resnet, name='dcn{}/encoder/sum_a{}'.format(self.label, 0))\n",
    "\n",
    "        resnet = tf.contrib.layers.conv2d(net, 128, 3, stride=1, activation_fn=activation, scope='dcn{}/encoder/conv_{}'.format(self.label, 4))\n",
    "        resnet = tf.contrib.layers.conv2d(resnet, 128, 3, stride=1, activation_fn=None, scope='dcn{}/encoder/conv_{}'.format(self.label, 5))\n",
    "        net = tf.add(net, resnet, name='dcn{}/encoder/sum_b{}'.format(self.label, 1))\n",
    "\n",
    "        resnet = tf.contrib.layers.conv2d(net, 128, 3, stride=1, activation_fn=activation, scope='dcn{}/encoder/conv_{}'.format(self.label, 6))\n",
    "        resnet = tf.contrib.layers.conv2d(resnet, 128, 3, stride=1, activation_fn=None, scope='dcn{}/encoder/conv_{}'.format(self.label, 7))\n",
    "        net = tf.add(net, resnet, name='dcn{}/encoder/sum_c{}'.format(self.label, 2))\n",
    "        \n",
    "        net = tf.contrib.layers.conv2d(net, 96, 5, stride=2, activation_fn=None, scope='dcn{}/encoder/conv_{}'.format(self.label, 8))\n",
    "        \n",
    "        latent = tf.identity(net, name='dcn{}/latent'.format(self.label))\n",
    "                \n",
    "        inet = tf.contrib.layers.conv2d(latent, 512, 3, stride=1, activation_fn=None, scope='dcn{}/decoder/conv_{}'.format(self.label, 0))\n",
    "        inet = tf.depth_to_space(inet, 2, name='dcn{}/decoder/d2s_{}'.format(self.label, 0))\n",
    "        \n",
    "        resnet = tf.contrib.layers.conv2d(inet, 128, 3, stride=1, activation_fn=activation, scope='dcn{}/decoder/conv_{}'.format(self.label, 1))\n",
    "        resnet = tf.contrib.layers.conv2d(resnet, 128, 3, stride=1, activation_fn=None, scope='dcn{}/decoder/conv_{}'.format(self.label, 2))\n",
    "        inet = tf.add(inet, resnet, name='dcn{}/decoder/sum_a{}'.format(self.label, 0))\n",
    "        \n",
    "        resnet = tf.contrib.layers.conv2d(inet, 128, 3, stride=1, activation_fn=activation, scope='dcn{}/decoder/conv_{}'.format(self.label, 3))\n",
    "        resnet = tf.contrib.layers.conv2d(resnet, 128, 3, stride=1, activation_fn=None, scope='dcn{}/decoder/conv_{}'.format(self.label, 4))\n",
    "        inet = tf.add(inet, resnet, name='dcn{}/decoder/sum_b{}'.format(self.label, 1))\n",
    "        \n",
    "        resnet = tf.contrib.layers.conv2d(inet, 128, 3, stride=1, activation_fn=activation, scope='dcn{}/decoder/conv_{}'.format(self.label, 5))\n",
    "        resnet = tf.contrib.layers.conv2d(resnet, 128, 3, stride=1, activation_fn=None, scope='dcn{}/decoder/conv_{}'.format(self.label, 6))\n",
    "        inet = tf.add(inet, resnet, name='dcn{}/decoder/sum_c{}'.format(self.label, 2))\n",
    "\n",
    "        inet = tf.contrib.layers.conv2d(inet, 256, 3, stride=1, activation_fn=activation, scope='dcn{}/decoder/tconv_{}'.format(self.label, 7))\n",
    "        inet = tf.depth_to_space(inet, 2, name='dcn{}/decoder/d2s_{}'.format(self.label, 7))\n",
    "        \n",
    "        inet = tf.contrib.layers.conv2d(inet, 12, 3, stride=1, activation_fn=None, scope='dcn{}/decoder/tconv_{}'.format(self.label, 8))\n",
    "        inet = tf.depth_to_space(inet, 2, name='dcn{}/decoder/d2s_{}'.format(self.label, 8))\n",
    "        \n",
    "        with tf.name_scope('dcn{}/denormalization'.format(self.label)):\n",
    "            y = (inet + 1) / 2\n",
    "            \n",
    "        y = tf.identity(y, name=\"y\")\n",
    "\n",
    "        with tf.name_scope('dcn{}/optimization'.format(self.label)):\n",
    "            lr = tf.placeholder(tf.float32, name='dcn_learning_rate')\n",
    "            loss = tf.nn.l2_loss(self.x - y)\n",
    "            adam = tf.train.AdamOptimizer(learning_rate=lr)\n",
    "            opt = adam.minimize(loss, var_list=self.parameters)\n",
    "            \n",
    "        return y, lr, loss, adam, opt, latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResDCN(compression.DCN):\n",
    "    \n",
    "    def construct_model(self):\n",
    "        \n",
    "        with tf.name_scope('dcn'):\n",
    "\n",
    "            activation = tf.nn.ResDCN\n",
    "            last_activation = tf.nn.sigmoid\n",
    "\n",
    "            print('Building Deep Compression Network with d-latent={}'.format(n_latent))\n",
    "\n",
    "            net = self.x\n",
    "            print('net size: {}'.format(net.shape))\n",
    "        \n",
    "            # Convolutions\n",
    "            n_filters = self.n_filters\n",
    "            \n",
    "            net = tf.contrib.layers.conv2d(net, 64, self.kernel, stride=2, activation_fn=activation, scope='dcn{}/conv_{}'.format(self.label, 0))\n",
    "            \n",
    "            for r in range(self.n_layers):\n",
    "                net = tf.contrib.layers.conv2d(net, n_filters, self.kernel, stride=2, activation_fn=activation, scope='dcn{}/conv_{}'.format(self.label, r))\n",
    "            #     print('net size: {}'.format(net.shape))\n",
    "#                     net = tf.contrib.layers.max_pool2d(net, 2, scope='dcn{}/pool_{}'.format(self.label, r))\n",
    "                print('net size: {} // {}'.format(net.shape, net))\n",
    "                n_filters *= self.n_fscale\n",
    "\n",
    "            # Flatten and get latent representation\n",
    "            flat = tf.contrib.layers.flatten(net, scope='dcn{}/flat_{}'.format(self.label, 0))\n",
    "            print('net size: {}'.format(flat.shape))\n",
    "\n",
    "            latent = tf.contrib.layers.fully_connected(flat, self.n_latent, activation_fn=activation, scope='dcn{}/dense_{}'.format(self.label, 0))\n",
    "            print('net size: {}'.format(latent.shape))\n",
    "\n",
    "            inet = tf.contrib.layers.fully_connected(latent, int(flat.shape[-1]), activation_fn=activation, scope='dcn{}/dense_{}'.format(self.label, 1))\n",
    "            print('net size: {}'.format(inet.shape))\n",
    "            inet = tf.reshape(net, tf.shape(net), name='dcn{}/reshape_{}'.format(self.label, 0))\n",
    "            print('net size: {}'.format(inet.shape))\n",
    "\n",
    "            # Transposed convolutions\n",
    "            for r in range(self.n_layers):\n",
    "                inet = tf.contrib.layers.conv2d_transpose(inet, 3 if r == self.n_layers - 1 else n_filters, self.kernel, stride=2, \n",
    "                                                          activation_fn=last_activation if r == self.n_layers - 1 else activation,\n",
    "                                                          scope='dcn{}/tconv_{}'.format(self.label, r))\n",
    "                print('net size: {}'.format(inet.shape))\n",
    "                n_filters = n_filters // self.n_fscale\n",
    "\n",
    "            y = inet\n",
    "\n",
    "        with tf.name_scope('dcn{}_optimization'.format(self.label)):\n",
    "            lr = tf.placeholder(tf.float32, name='dcn_learning_rate')\n",
    "            loss = tf.nn.l2_loss(self.x - y)\n",
    "            adam = tf.train.AdamOptimizer(learning_rate=lr)\n",
    "            opt = adam.minimize(loss, var_list=self.parameters)\n",
    "            \n",
    "        return y, lr, loss, adam, opt, latent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create DCN instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_spatial = int(dcn.patch_size / (2**dcn.n_layers))\n",
    "z_filters = int(dcn.n_filters * (dcn.n_fscale**(dcn.n_layers-1)))\n",
    "shape = (None, z_spatial, z_spatial, z_filters)\n",
    "print(shape)\n",
    "# alphas = tf.get_variable('dcn{}/latent_scaling'.format(self.label), shape=(None, z_spatial, z_spatial, z_filters), dtype=tf.float32, initializer=tf.ones_initializer)\n",
    "\n",
    "alphas = tf.get_variable('dcn{}/latent_scaling'.format(dcn.label), shape=(None, 100), dtype=tf.float32, initializer=tf.ones_initializer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "sess = tf.Session(graph=graph)\n",
    "\n",
    "# dcn = AutoencoderDCN(sess, graph, patch_size=training['patch_size'], n_latent=0, n_layers=3, n_fscale=2, n_filters=8, dropout=True)\n",
    "dcn = AutoencoderDCN(sess, graph, patch_size=training['patch_size'], n_latent=0, n_filters=8, n_fscale=2, n_layers=3, r_layers=0, \n",
    "                     dropout=True, is_training=True, train_codebook=True, latent_bpf=6, scale_latent=False, entropy_weight=None)\n",
    "\n",
    "# dcn = TwitterDCN(sess, graph, patch_size=128)\n",
    "\n",
    "print(dcn.summary())\n",
    "print(dcn.short_name())\n",
    "# print(dcn.count_parameters_breakdown())\n",
    "print('Compression stats:', dcn.compression_stats(n_latent_bytes=0.5))\n",
    "\n",
    "# dcn.load_model('./data/raw/compression/aedcn/8x8x192')\n",
    "# dcn.save_model(os.path.join('./data/raw/compression/', dcn.short_name()), 3767)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import tf_helpers\n",
    "tf_helpers.show_graph(dcn.graph.as_graph_def())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dcn.init()\n",
    "out = dcn.sess.run(dcn.weights, feed_dict={dcn.x: batch_x})\n",
    "# fig = plotting.imsc(out[0:32, :])\n",
    "\n",
    "with dcn.graph.as_default():\n",
    "    histogram = dcn.sess.run(dcn.histogram, feed_dict={dcn.x: batch_x})\n",
    "    entropy = dcn.sess.run(- tf.reduce_sum(dcn.histogram * tf.log(dcn.histogram)) / 0.6931, feed_dict={dcn.x: batch_x})\n",
    "\n",
    "plt.plot(histogram)\n",
    "print(entropy)\n",
    "\n",
    "print(- np.sum(histogram * np.log2(histogram)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcn.init()\n",
    "\n",
    "# Compute the number of available batches\n",
    "n_batches = data['training']['y'].shape[0] // training['batch_size']\n",
    "v_batches = data['validation']['y'].shape[0] // training['batch_size']\n",
    "\n",
    "# Structures for storing performance stats\n",
    "perf = {\n",
    "    'loss': {'training': [], 'validation': []},\n",
    "    'entropy': {'training': [], 'validation': []},\n",
    "    'ssim': {'training': [], 'validation': []}\n",
    "}\n",
    "\n",
    "caches = {\n",
    "    'loss': {'training': deque(maxlen=n_batches), 'validation': deque(maxlen=v_batches)},\n",
    "    'entropy': {'training': deque(maxlen=n_batches), 'validation': deque(maxlen=v_batches)},\n",
    "    'ssim': {'training': deque(maxlen=n_batches), 'validation': deque(maxlen=v_batches)}\n",
    "}\n",
    "\n",
    "# Configure data augmentation\n",
    "augmentation_probs = {\n",
    "    'resize': 0.0,\n",
    "    'flip_h': 0.5,\n",
    "    'flip_v': 0.5\n",
    "}\n",
    "\n",
    "sample_dropout = False\n",
    "learning_rate = 1e-4\n",
    "sampling_rate = 100\n",
    "\n",
    "model_output_dirname = os.path.join('./data/raw/compression/', dcn.short_name())\n",
    "\n",
    "# Create a summary writer and create the necessary directories\n",
    "sw = dcn.get_summary_writer(model_output_dirname)\n",
    "\n",
    "with tqdm.tqdm(total=training['n_epochs'], ncols=160, desc='Train') as pbar:\n",
    "\n",
    "    for epoch in range(0, training['n_epochs']):\n",
    "        \n",
    "        if epoch> 0 and epoch % 1000 == 0:\n",
    "            learning_rate = learning_rate / 2\n",
    "\n",
    "        # Iterate through batches of the training data \n",
    "        for batch_id in range(n_batches): # TODO n_batches\n",
    "            \n",
    "            # Pick random patch size - will be resized later for augmentation\n",
    "            current_patch = np.random.choice(np.arange(training['patch_size'], 2 * training['patch_size']), 1) if np.random.uniform() < augmentation_probs['resize'] else training['patch_size']\n",
    "            \n",
    "            # Sample next batch\n",
    "            batch_x = data.next_training_batch(batch_id, training['batch_size'], current_patch)\n",
    "            \n",
    "            # If rescaling needed, apply\n",
    "            if training['patch_size'] != current_patch:\n",
    "                batch_t = np.zeros((batch_x.shape[0], training['patch_size'], training['patch_size'], 3), dtype=np.float32)\n",
    "                for i in range(len(batch_x)):\n",
    "                    batch_t[i] = resize(batch_x[i], [training['patch_size'], training['patch_size']], anti_aliasing=True)\n",
    "                batch_x = batch_t                \n",
    "            \n",
    "            # Data augmentation - random horizontal flip\n",
    "            if np.random.uniform() < augmentation_probs['flip_h']: batch_x = batch_x[:, :, ::-1, :]\n",
    "            if np.random.uniform() < augmentation_probs['flip_v']: batch_x = batch_x[:, ::-1, :, :]\n",
    "            \n",
    "            # Sample dropout\n",
    "            keep_prob = 1.0 if not sample_dropout else np.random.uniform(0.5, 1.0)            \n",
    "            \n",
    "            # Make a training step\n",
    "            values = dcn.training_step(batch_x, learning_rate, dropout_keep_prob=keep_prob)\n",
    "            for key, value in values.items():\n",
    "                caches[key]['training'].append(value)                \n",
    "            \n",
    "        # Record average values for the whole epoch\n",
    "        for key in ['loss', 'ssim', 'entropy']:\n",
    "            perf[key]['training'].append(np.mean(caches[key]['training']))\n",
    "\n",
    "        # Get some extra stats\n",
    "        if dcn.scale_latent:\n",
    "            scaling = dcn.sess.run(dcn.graph.get_tensor_by_name('dcn/latent_scaling:0'))\n",
    "        else:\n",
    "            scaling = np.nan\n",
    "            \n",
    "        codebook = dcn.sess.run(dcn.codebook)        \n",
    "\n",
    "        # Iterate through batches of the validation data\n",
    "        if epoch % sampling_rate == 0:\n",
    "            for batch_id in range(v_batches): # TODO v_batches\n",
    "                batch_x = data.next_validation_batch(batch_id, training['batch_size'], training['patch_size'])\n",
    "                batch_y = dcn.process(batch_x)\n",
    "                \n",
    "                # Compute loss\n",
    "                loss_value = np.linalg.norm(batch_x - batch_y)\n",
    "                caches['loss']['validation'].append(loss_value)                \n",
    "                \n",
    "                # Compute SSIM            \n",
    "#                 ssim_value = np.mean([ssim((255*batch_x[r]).astype(np.uint8), (255*batch_y[r]).astype(np.uint8)) for r in range(len(batch_x))])\n",
    "                ssim_value = np.mean([ssim(batch_x[r], batch_y[r], multichannel=True) for r in range(len(batch_x))]) \n",
    "                caches['ssim']['validation'].append(ssim_value)\n",
    "\n",
    "            perf['loss']['validation'].append(np.mean(caches['loss']['validation']))\n",
    "            perf['ssim']['validation'].append(np.mean(caches['ssim']['validation']))\n",
    "            \n",
    "            # Save current snapshot\n",
    "            thumbs = (255 * plotting.thumbnails(np.concatenate((batch_x[::2], batch_y[::2]), axis=0), n_cols=20)).astype(np.uint8)\n",
    "            thumbs_few = (255 * plotting.thumbnails(np.concatenate((batch_x[::10], batch_y[::10]), axis=0), n_cols=4)).astype(np.uint8)\n",
    "            imageio.imsave(os.path.join(model_output_dirname, 'thumbnails-{:05d}.png'.format(epoch)), thumbs)\n",
    "            \n",
    "            # Sample latent space\n",
    "            batch_z = dcn.compress(batch_x) # data.next_validation_batch(0, 256)\n",
    "        \n",
    "            # Save summaries to TB            \n",
    "            summary = tf.Summary()\n",
    "            summary.value.add(tag='loss/validation', simple_value=perf['loss']['validation'][-1])\n",
    "            summary.value.add(tag='loss/training', simple_value=perf['loss']['training'][-1])\n",
    "            summary.value.add(tag='ssim/validation', simple_value=perf['ssim']['validation'][-1])\n",
    "            summary.value.add(tag='ssim/training', simple_value=perf['ssim']['training'][-1])\n",
    "            summary.value.add(tag='entropy/training', simple_value=perf['entropy']['training'][-1])\n",
    "            summary.value.add(tag='codebook/min', simple_value=codebook.min())\n",
    "            summary.value.add(tag='codebook/max', simple_value=codebook.max())\n",
    "            summary.value.add(tag='codebook/mean', simple_value=codebook.mean())\n",
    "            summary.value.add(tag='codebook/diff_variance', simple_value=np.var(np.convolve(code_book, [-1, 1], mode='valid')))\n",
    "            summary.value.add(tag='scaling', simple_value=scaling)\n",
    "            summary.value.add(tag='images/reconstructed', image=summaries.log_image(rescale(thumbs_few, 1.0, anti_aliasing=True)))\n",
    "            summary.value.add(tag='histograms/latent', histo=summaries.log_histogram(batch_z))\n",
    "            sw.add_summary(summary, epoch)\n",
    "            sw.flush()        \n",
    "\n",
    "        # Update progress bar\n",
    "        pbar.set_postfix(L=np.mean(perf['loss']['training'][-3:]), \n",
    "                         Lv=np.mean(perf['loss']['validation'][-1:]),\n",
    "#                          lr='{:.8f}'.format(learning_rate),\n",
    "                         ssim=perf['ssim']['validation'][-1],\n",
    "                         H=np.mean(perf['entropy']['training'][-1:]), \n",
    "                         S=scaling,\n",
    "                         Qvar=np.var(np.convolve(code_book, [-1, 1], mode='valid'))\n",
    "                        )\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcn.save_model(model_output_dirname, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from helpers import utils\n",
    "\n",
    "fig = plt.figure(figsize=(20, 4))\n",
    "ax = fig.gca()\n",
    "ax.plot(utils.ma_conv(perf['loss']['training'], n=11))\n",
    "# ax.plot(np.arange(0, len(loss['training']), sampling_rate), utils.ma_conv(loss['validation'], n=3))\n",
    "ax.plot(np.arange(0, len(perf['loss']['training']), sampling_rate), perf['loss']['validation'], '-o', alpha=0.3)\n",
    "ax.plot(perf['loss']['training'], '.', alpha=0.1)\n",
    "ax.legend(['train', 'valid'], loc='upper right')\n",
    "# ax.set_yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcn.load_model(os.path.join('./data/raw/compression/', dcn.short_name()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show a sample and a reconstruction of the current batch\n",
    "batch_y = dcn.process(batch_x)\n",
    "f = plotting.imsc(batch_x[0:8], ncols=8, figwidth=20)\n",
    "f = plotting.imsc(batch_y[0:8], ncols=8, figwidth=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore & Understand the Latent Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate entropy\n",
    "sample_batch_size = 400\n",
    "\n",
    "batch_x = data.next_validation_batch(0, sample_batch_size)\n",
    "\n",
    "# See latent distribution\n",
    "batch_z = dcn.compress(batch_x)\n",
    "batch_z = batch_z.reshape((sample_batch_size, -1)).T\n",
    "print(batch_z.shape)\n",
    "\n",
    "feature_id = 1\n",
    "\n",
    "# data = batch_z[feature_id]\n",
    "\n",
    "n_bins = 128\n",
    "bin_boundaries = np.linspace(-32, 32, n_bins+1)\n",
    "bin_centers = np.convolve(bin_boundaries, [0.5, 0.5], mode='valid')\n",
    "\n",
    "# for bin, value in zip(bin_centers, hist):\n",
    "#     print(bin, '->', value)   \n",
    "\n",
    "hist = np.histogram(batch_z[:], bins=bin_boundaries, normed=True)[0]\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.gca()\n",
    "ax.bar(bin_centers, hist, width=bin_centers[1] - bin_centers[0], color='r')\n",
    "ax.set_title('Histogram of quantized coefficients')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# q_min = np.percentile(batch_z.astype(np.int32), 0.1)\n",
    "# q_max = np.percentile(batch_z.astype(np.int32), 100 - 0.1)\n",
    "\n",
    "q_min = np.percentile(batch_z.astype(np.int32), 0.1)\n",
    "q_max = np.percentile(batch_z.astype(np.int32), 100 - 0.1)\n",
    "\n",
    "\n",
    "bin_boundaries = np.arange(q_min + 0.5, q_max + 0.5, 1)\n",
    "bin_centers = np.convolve(bin_boundaries, [0.5, 0.5], mode='valid')\n",
    "\n",
    "print('Bin centers ({}): {}'.format(len(bin_centers), bin_centers.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# value = np.array([[-3.1231]])\n",
    "batch_ex = batch_z.T[0]\n",
    "value = batch_ex.reshape((4096, 1))\n",
    "\n",
    "sigma = 3\n",
    "weights = np.exp(-sigma * np.power(value - bin_centers.reshape(1, len(bin_centers)), 2))\n",
    "weights = weights / weights.sum(axis=1, keepdims=True)\n",
    "\n",
    "feature_id = 20\n",
    "print('Feature', feature_id)\n",
    "print('Value', value[feature_id])\n",
    "print('Quantization', np.round(value[feature_id]))\n",
    "print('Soft quantization', np.sum(weights[feature_id] * bin_centers))\n",
    "\n",
    "# \n",
    "plt.plot(bin_centers, weights[feature_id])\n",
    "plt.title('{} / {}'.format(batch_ex[feature_id], np.sum(soft[feature_id])))\n",
    "\n",
    "# plt.plot(bin_centers, weights.squeeze())\n",
    "# plt.title('{} / {}'.format(value, np.sum(weights)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute frequencies using unique\n",
    "indices, _ = vq(batch_z.reshape((-1, )), bin_centers)\n",
    "unique, counts = np.unique(bin_centers[indices], return_counts=True)\n",
    "counts = counts / counts.sum()\n",
    "\n",
    "# Compute soft histogram\n",
    "histogram = np.mean(weights, axis=0).clip(1e-6)\n",
    "histogram = histogram / np.sum(histogram)\n",
    "\n",
    "entropy_estimate = - np.sum(histogram * np.log2(histogram))\n",
    "\n",
    "plt.plot(unique, counts)\n",
    "plt.plot(bin_centers, histogram)\n",
    "plt.legend(['unique', 'soft'])\n",
    "plt.title('Soft-estimated entropy {:.2f}'.format(entropy_estimate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entropy Coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_min = np.percentile(batch_z.astype(np.int32), 0.1)\n",
    "q_max = np.percentile(batch_z.astype(np.int32), 100 - 0.1)\n",
    "\n",
    "bin_boundaries = np.arange(q_min + 0.5, q_max - 0.5, 1)\n",
    "bin_centers = np.convolve(bin_boundaries, [0.5, 0.5], mode='valid')\n",
    "\n",
    "# print(bin_boundaries)\n",
    "\n",
    "# Compute frequencies using a histogram\n",
    "freq = np.histogram(batch_z[:], bins=bin_boundaries, normed=False)[0]\n",
    "hist = np.histogram(batch_z[:], bins=bin_boundaries, normed=True)[0]\n",
    "hist = hist.clip(1e-9)\n",
    "probs = hist / np.sum(hist)\n",
    "\n",
    "# Compute frequencies using unique\n",
    "indices, _ = vq(batch_z.reshape((-1, )), bin_centers)\n",
    "unique, counts = np.unique(bin_centers[indices], return_counts=True)\n",
    "\n",
    "print('Bin centers - {} values'.format(len(bin_centers)))\n",
    "for bin, value in zip(bin_centers, freq):\n",
    "    print('  ',bin, '->', value.round(2))   \n",
    "\n",
    "# print(hist.round(2))\n",
    "# print(probs.round(2))\n",
    "\n",
    "entropy = np.sum(- probs * np.log2(probs))\n",
    "\n",
    "print('Naive coding: {:.2f}'.format(np.log2(len(bin_centers))))\n",
    "print('Entropy: {:.2f}'.format(entropy))\n",
    "\n",
    "from dahuffman import HuffmanCodec\n",
    "\n",
    "codec = HuffmanCodec.from_frequencies({k: v for k, v in zip(bin_centers.astype(np.int), freq)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{k: v for k, v in zip(bin_centers.astype(np.int), probs)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word codec.get_code_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.vq import vq\n",
    "\n",
    "print(batch_z.T[0].shape)\n",
    "\n",
    "code_book = bin_centers.astype(np.int)\n",
    "\n",
    "# Vector quantization\n",
    "indices, distortion = vq(batch_z.T[0], code_book)\n",
    "batch_q = code_book[indices]\n",
    "\n",
    "print('Codebook {}: {}'.format(len(code_book), code_book))\n",
    "print(batch_z.T[0])\n",
    "print(batch_q)\n",
    "print(indices)\n",
    "\n",
    "encoded = codec.encode(batch_q)\n",
    "bits_per_symbol = np.ceil(np.log2(len(bin_centers)))\n",
    "\n",
    "print('Naive coding: {:.0f} bytes'.format(bits_per_symbol * len(batch_q) / 8))\n",
    "print('Theoretical limit: {:.0f} bytes'.format(entropy * len(batch_q) / 8))\n",
    "print('Compressed (Huffman): {} bytes'.format(len(encoded)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codec.print_code_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_output_dirname = os.path.join('./data/raw/compression/', dcn.short_name(), 'raise')\n",
    "dcn.load_model(model_output_dirname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import plotting\n",
    "\n",
    "# dcn.init()\n",
    "\n",
    "batch_x = data.next_validation_batch(0, 256)\n",
    "\n",
    "# See latent distribution\n",
    "# batch_z = dcn.compress(batch_x).T\n",
    "batch_z = dcn.compress(batch_x).reshape((256, -1)).T\n",
    "# batch_z = batch_x.reshape((256, 128*128*3)).T\n",
    "print(batch_z.shape)\n",
    "\n",
    "# cov = batch_z.T * batch_z\n",
    "\n",
    "# cov = np.cov(batch_z)\n",
    "\n",
    "cov = np.corrcoef(batch_z)\n",
    "\n",
    "plt.imshow(cov)\n",
    "\n",
    "# batch_z = batch_z[:9]\n",
    "\n",
    "# fig, axes = plotting.sub(len(batch_z) + 1, ncols=10, figwidth=20)\n",
    "\n",
    "# # print(axes)\n",
    "\n",
    "# for i, ax in enumerate(axes):\n",
    "   \n",
    "#     if i >= len(batch_z):\n",
    "#         plotting.quickshow(cov)\n",
    "#     else:        \n",
    "#         ax.hist(batch_z[i], bins=30)\n",
    "#         ax.set_yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_centers = [-3, -2, -1, 0, 1, 2, 3]\n",
    "p, x = np.histogram(np.random.normal(size=(1000,)), bins=bin_centers)\n",
    "print(bin_centers)\n",
    "print(x)\n",
    "print(np.convolve(x, [0.5, 0.5], mode='valid'))\n",
    "print(p)\n",
    "plt.plot(np.convolve(x, [0.5, 0.5], mode='valid'), p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_means = np.mean(batch_z,axis=1)\n",
    "fig, axes = plotting.sub(2, figwidth=12)\n",
    "axes[0].plot(latent_means)\n",
    "axes[0].set_title('Mean values for all latent variables')\n",
    "axes[1].hist(latent_means, bins=50, normed=True)\n",
    "axes[1].set_title('Histogram of mean values for all latent variables')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_x = data.next_validation_batch(0, 400)\n",
    "\n",
    "batch_z = dcn.compress(batch_x)\n",
    "batch_z = batch_z.reshape((sample_batch_size, -1)).T\n",
    "print(batch_z.shape)\n",
    "\n",
    "n_bins = 64\n",
    "bin_boundaries = np.linspace(-16, 16, n_bins+1)\n",
    "bin_centers = np.convolve(bin_boundaries, [0.5, 0.5], mode='valid')\n",
    "\n",
    "print(bin_centers)\n",
    "\n",
    "distribution = np.zeros((len(batch_z), n_bins))\n",
    "for i in range(len(batch_z)):\n",
    "    distribution[i, :] = np.histogram(batch_z[i], bins=bin_boundaries, normed=True)[0]\n",
    "\n",
    "vis = []\n",
    "for i in range(len(distribution) // 512):\n",
    "    vis.append(distribution[i*512:(i+1)*512, :])\n",
    "    \n",
    "\n",
    "thumbs = plotting.thumbnails(vis, n_cols=len(vis))\n",
    "    \n",
    "fig = plotting.imsc(thumbs, 'A', figwidth=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_bins = 64\n",
    "bin_boundaries = np.linspace(-256, 256, n_bins+1)\n",
    "bin_centers = np.convolve(bin_boundaries, [0.5, 0.5], mode='valid')\n",
    "\n",
    "i = 58\n",
    "fig = plt.figure(figsize=(16, 4))\n",
    "fig.gca().fill_between(bin_centers, 0, np.histogram(batch_z[i], bins=bin_boundaries, normed=True)[0], alpha=0.1)\n",
    "print(distribution[i, :])\n",
    "print(batch_z[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16, 4))\n",
    "for i in range(len(batch_z)):\n",
    "#     fig.gca().plot(bin_centers, distribution[i, :])\n",
    "    fig.gca().fill_between(bin_centers, 0, distribution[i, :], alpha=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for op in dcn.sess.graph.get_operations():\n",
    "    print(op.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantization of the latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.vq import vq\n",
    "\n",
    "code_book = np.array([-1, 0, 1])\n",
    "\n",
    "batch_x = data.next_validation_batch(0, 256)\n",
    "\n",
    "alpha = 1\n",
    "n_unique = 64\n",
    "\n",
    "# See latent distribution\n",
    "# batch_z = dcn.compress(batch_x).T\n",
    "batch_z = dcn.compress(batch_x)\n",
    "# print(batch_z[0, 0:15].round(3))\n",
    "# batch_z = batch_z.clip(-100, 100)\n",
    "# batch_z = (alpha * batch_z).astype(np.int32) / alpha\n",
    "# batch_z = ((alpha * batch_z).astype(np.int32).clip(-n_unique // 2 + 1, n_unique // 2) / alpha)\n",
    "# print(batch_z[0, 0:15])\n",
    "print('Int from {} to {}'.format(-n_unique // 2 + 1, n_unique // 2))\n",
    "print('  unique = {}'.format(np.unique(batch_z)))\n",
    "print('# unique = {}'.format(len(np.unique(batch_z))))\n",
    "\n",
    "# Vector quantization\n",
    "# indices, distortion = vq(batch_z, code_book)\n",
    "# batch_z = code_book[indices]\n",
    "\n",
    "batch_y = dcn.decompress(batch_z)\n",
    "\n",
    "f = plotting.imsc(batch_x[0:8], ncols=8, figwidth=20)\n",
    "f = plotting.imsc(batch_y[0:8], ncols=8, figwidth=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_id = 0\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "fig.gca().hist(batch_z[dim_id])\n",
    "print(batch_z[dim_id].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcn.save_model('./data/raw/compression/aedcn/8x8x192', epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the actual bitstream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_min = -16\n",
    "q_max = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "sess = tf.Session(graph=graph)\n",
    "\n",
    "dcn = AutoencoderDCN(sess, graph, patch_size=training['patch_size'], n_latent=0, n_layers=3, n_fscale=2, n_filters=16, dropout=0.5, is_training=True)\n",
    "# dcn = AutoencoderDCN(sess, graph, patch_size=512, n_latent=0, n_layers=3, n_fscale=2, n_filters=16, dropout=0.5, is_training=True)\n",
    "# model_output_dirname = os.path.join('./data/raw/compression/', dcn.short_name(), '128x128_bn_mult_no_entropy')\n",
    "dcn.load_model(model_output_dirname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'dcn/encoder/bn_0/moving_mean'\n",
    "dcn.parameters\n",
    "with dcn.graph.as_default():\n",
    "    for tv in [tv for tv in tf.trainable_variables()]:\n",
    "        print(tv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.vq import vq\n",
    "\n",
    "max_value = 32\n",
    "\n",
    "qmin = -max_value\n",
    "qmax = max_value + 2\n",
    "step = 1\n",
    "\n",
    "code_book = np.arange(qmin, qmax, step)\n",
    "code_book_edges = np.convolve(code_book, [0.5, 0.5], mode='valid')\n",
    "code_book = code_book[1:-1]\n",
    "\n",
    "image = imageio.imread('./data/clic/alberto-montalesi-176097.png').astype(np.float32) / (2**8 - 1)\n",
    "batch_x = utils.slidingwindow(image, 128)[6:7]\n",
    "\n",
    "# See latent distribution\n",
    "# batch_z = dcn.compress(batch_x).T\n",
    "batch_z = dcn.compress(batch_x)\n",
    "\n",
    "print('Codebook size: {} // {}'.format(len(code_book), code_book.tolist()))\n",
    "\n",
    "# Compute frequencies using unique\n",
    "indices, _ = vq(batch_z.reshape((-1, )), code_book)\n",
    "counts = np.histogram(code_book[indices], bins=code_book_edges)[0]\n",
    "\n",
    "plt.plot(code_book, counts)\n",
    "\n",
    "# Construct a Huffman codec\n",
    "codec = HuffmanCodec.from_frequencies({k: v for k, v in zip(code_book.astype(np.int), counts)})\n",
    "\n",
    "# Vector quantization\n",
    "indices, distortion = vq(batch_z.reshape((-1)), code_book)\n",
    "batch_q = code_book[indices]\n",
    "\n",
    "# Zero some elements\n",
    "\n",
    "# batch_q[np.random.uniform(size=batch_q.shape) > 0.1] = 0\n",
    "\n",
    "batch_y = dcn.decompress(batch_q.reshape(dcn.latent_shape))\n",
    "\n",
    "coded_image = codec.encode(batch_q.tolist())\n",
    "\n",
    "ssim_value = ssim(batch_x[0], batch_y[0], multichannel=True)\n",
    "\n",
    "counts = counts.clip(min=1)\n",
    "probs = counts / counts.sum()\n",
    "entropy = - np.sum(probs * np.log2(probs))\n",
    "\n",
    "print('Pixels          : {}x{} = {:,}'.format(128, 128, 128*128))\n",
    "print('Bitmap          : {:,} bytes'.format(128*128*3))\n",
    "print('Batch size      : {:,} elements'.format(np.prod(batch_x.shape)))\n",
    "print('Code-book size  : {} elements'.format(len(code_book)))\n",
    "print('Entropy         : {:.2f} bits per symbol'.format(entropy))\n",
    "print('Latent size     : {:,}'.format(np.prod(batch_z.shape)))\n",
    "print('PPF Naive       : {:,.0f} --> {:,.0f} bytes [{} bits per element]'.format(np.prod(batch_z.shape) * np.log2(len(code_book)) / 8,\n",
    "                                               np.prod(batch_z.shape) * np.ceil(np.log2(len(code_book))) / 8,\n",
    "                                               np.ceil(np.log2(len(code_book)))\n",
    "                                              ))\n",
    "print('PPF Theoretical : {:,.0f} bytes'.format(np.prod(batch_z.shape) * entropy / 8))\n",
    "print('PPF Huffman     : {:,} bytes ({:.2f} bpp) --> ssim: {:.2f}'.format(len(coded_image), \n",
    "                                                              8 * len(coded_image) / np.prod(batch_x.shape[1:3]),\n",
    "                                                              ssim_value,\n",
    "                                                             ))\n",
    "# Encode JPEG\n",
    "s = io.BytesIO()\n",
    "imageio.imsave(s, (255*batch_x).astype(np.uint8).squeeze(), format='jpg', quality=20)\n",
    "# imageio.imsave('test.jpg', (255*batch_x).astype(np.uint8).squeeze(), format='jpg', quality=50)\n",
    "image_compressed = imageio.imread(s.getvalue())\n",
    "batch_j = np.expand_dims(image_compressed, axis=0) / (2**8 - 1)\n",
    "\n",
    "ssim_value = ssim(batch_x[0], batch_j[0], multichannel=True)\n",
    "\n",
    "print('JPEG stream     : {:,} bytes ({:0.2f} bpp) --> ssim: {:.2f}'.format(len(s.getvalue()), 8 * len(s.getvalue()) / np.prod(batch_j.shape[1:3]), ssim_value ))\n",
    "\n",
    "f = plotting.imsc(np.concatenate((batch_x[0:8], batch_y[0:8], batch_j[0:8]), axis=0), ncols=3 * len(batch_x), figwidth=14)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
