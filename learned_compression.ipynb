{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tqdm\n",
    "\n",
    "from collections import deque\n",
    "from skimage.transform import resize\n",
    "\n",
    "# Own libraries and modules\n",
    "from helpers import loading, plotting, utils\n",
    "from models import compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = {\n",
    "    'n_epochs': 3000,\n",
    "    'batch_size': 32,\n",
    "    'patch_size': 128\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_size = 128\n",
    "n_latent = 256\n",
    "n_latent_bytes = 2\n",
    "\n",
    "bitmap_size = patch_size*patch_size*3\n",
    "compression_rate = bitmap_size / (n_latent_bytes * n_latent)\n",
    "compression_bpp = 8 * n_latent * n_latent_bytes / patch_size / patch_size\n",
    "\n",
    "print('Bitmap size: {:,d} bytes'.format(bitmap_size))\n",
    "print('Latent size: {:,}-D'.format(n_latent))\n",
    "print('Latent repr: {:,} bytes'.format(n_latent * n_latent_bytes))\n",
    "print('Compression rate: 1:{}'.format(compression_rate))\n",
    "print('Compression Fi  : {:.2f} bpp'.format(compression_bpp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IPDataset:\n",
    "    \n",
    "    def __init__(self, data_directory, randomize=False, load='xy', val_patch_size=128, val_n_patches=10):\n",
    "        self.files = {}\n",
    "        self.files['training'], self.files['validation'] = loading.discover_files(data_directory, randomize=randomize)\n",
    "                \n",
    "        self.data = {\n",
    "            'training': loading.load_images(self.files['training'], data_directory=data_directory, load=load),\n",
    "            'validation': loading.load_patches(self.files['validation'], data_directory=data_directory, patch_size=val_patch_size // 2, n_patches=val_n_patches, load=load, discard_flat=True)\n",
    "        }\n",
    "        \n",
    "        self.H, self.W = self.data['training']['x'].shape[1:3]\n",
    "        \n",
    "    def __getitem__(self, key):\n",
    "        if key in ['training', 'validation']:\n",
    "            return self.data[key]\n",
    "        else:\n",
    "            return super().__getitem__(key)\n",
    "        \n",
    "    def next_training_batch(self, batch_id, batch_size, patch_size):\n",
    "        batch_x = np.zeros((batch_size, patch_size, patch_size, 3), dtype=np.float32)\n",
    "        for b in range(training['batch_size']):\n",
    "            xx = np.random.randint(0, self.W - patch_size)\n",
    "            yy = np.random.randint(0, self.H - patch_size)\n",
    "            batch_x[b, :, :, :] = self.data['training']['y'][batch_id * batch_size + b, yy:yy + patch_size, xx:xx + patch_size, :].astype(np.float) / (2**8 - 1)\n",
    "        return batch_x\n",
    "\n",
    "    def next_validation_batch(self, batch_id, batch_size):\n",
    "        patch_size = self.data['validation']['y'].shape[1]\n",
    "        batch_x = np.zeros((batch_size, patch_size, patch_size, 3), dtype=np.float32)\n",
    "        for b in range(training['batch_size']):\n",
    "            batch_x[b, :, :, :] = self.data['validation']['y'][batch_id * batch_size + b].astype(np.float)\n",
    "        return batch_x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "camera_name = \"Nikon D90\"\n",
    "data_directory = os.path.join('./data/raw/nip_training_data/', camera_name)\n",
    "\n",
    "data = IPDataset(data_directory)\n",
    "\n",
    "for dataset in ['training', 'validation']:\n",
    "    print('{} : {}'.format(dataset, data[dataset]['y'].shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Deep Compression Network Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoencoderDCN(compression.DCN):\n",
    "    \n",
    "    def construct_model(self):\n",
    "        \n",
    "        with tf.name_scope('dcn'):\n",
    "\n",
    "            activation = tf.nn.leaky_relu\n",
    "            last_activation = tf.nn.sigmoid\n",
    "\n",
    "            print('Building Deep Compression Network with d-latent={}'.format(n_latent))\n",
    "\n",
    "            net = self.x\n",
    "            print('net size: {}'.format(net.shape))\n",
    "        \n",
    "            # Convolutions\n",
    "            n_filters = self.n_filters\n",
    "            \n",
    "            for r in range(self.n_layers):\n",
    "                net = tf.contrib.layers.conv2d(net, n_filters, self.kernel, stride=2, activation_fn=activation, scope='dcn{}/conv_{}'.format(self.label, r))\n",
    "            #     print('net size: {}'.format(net.shape))\n",
    "#                     net = tf.contrib.layers.max_pool2d(net, 2, scope='dcn{}/pool_{}'.format(self.label, r))\n",
    "                print('net size: {}'.format(net.shape))\n",
    "                n_filters *= self.n_fscale\n",
    "\n",
    "            # Flatten and get latent representation\n",
    "            flat = tf.contrib.layers.flatten(net, scope='dcn{}/flat_{}'.format(self.label, 0))\n",
    "            print('net size: {}'.format(flat.shape))\n",
    "\n",
    "            latent = tf.contrib.layers.fully_connected(flat, self.n_latent, activation_fn=activation, scope='dcn{}/dense_{}'.format(self.label, 0))\n",
    "            print('net size: {}'.format(latent.shape))\n",
    "\n",
    "            inet = tf.contrib.layers.fully_connected(latent, int(flat.shape[-1]), activation_fn=activation, scope='dcn{}/dense_{}'.format(self.label, 1))\n",
    "            print('net size: {}'.format(inet.shape))\n",
    "            inet = tf.reshape(net, tf.shape(net), name='dcn{}/reshape_{}'.format(self.label, 0))\n",
    "            print('net size: {}'.format(inet.shape))\n",
    "\n",
    "            # Transposed convolutions\n",
    "            for r in range(self.n_layers):\n",
    "                inet = tf.contrib.layers.conv2d_transpose(inet, 3 if r == self.n_layers - 1 else n_filters, self.kernel, stride=2, \n",
    "                                                          activation_fn=last_activation if r == self.n_layers - 1 else activation,\n",
    "                                                          scope='dcn{}/tconv_{}'.format(self.label, r))\n",
    "                print('net size: {}'.format(inet.shape))\n",
    "                n_filters = n_filters // self.n_fscale\n",
    "\n",
    "            y = inet\n",
    "\n",
    "        with tf.name_scope('dcn{}_optimization'.format(self.label)):\n",
    "            lr = tf.placeholder(tf.float32, name='dcn_learning_rate')\n",
    "            loss = tf.nn.l2_loss(self.x - y)\n",
    "            adam = tf.train.AdamOptimizer(learning_rate=lr)\n",
    "            opt = adam.minimize(loss, var_list=self.parameters)\n",
    "            \n",
    "        return y, lr, loss, adam, opt, latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResDCN(compression.DCN):\n",
    "    \n",
    "    def construct_model(self):\n",
    "        \n",
    "        with tf.name_scope('dcn'):\n",
    "\n",
    "            activation = tf.nn.ResDCN\n",
    "            last_activation = tf.nn.sigmoid\n",
    "\n",
    "            print('Building Deep Compression Network with d-latent={}'.format(n_latent))\n",
    "\n",
    "            net = self.x\n",
    "            print('net size: {}'.format(net.shape))\n",
    "        \n",
    "            # Convolutions\n",
    "            n_filters = self.n_filters\n",
    "            \n",
    "            net = tf.contrib.layers.conv2d(net, 64, self.kernel, stride=2, activation_fn=activation, scope='dcn{}/conv_{}'.format(self.label, 0))\n",
    "            \n",
    "            for r in range(self.n_layers):\n",
    "                net = tf.contrib.layers.conv2d(net, n_filters, self.kernel, stride=2, activation_fn=activation, scope='dcn{}/conv_{}'.format(self.label, r))\n",
    "            #     print('net size: {}'.format(net.shape))\n",
    "#                     net = tf.contrib.layers.max_pool2d(net, 2, scope='dcn{}/pool_{}'.format(self.label, r))\n",
    "                print('net size: {} // {}'.format(net.shape, net))\n",
    "                n_filters *= self.n_fscale\n",
    "\n",
    "            # Flatten and get latent representation\n",
    "            flat = tf.contrib.layers.flatten(net, scope='dcn{}/flat_{}'.format(self.label, 0))\n",
    "            print('net size: {}'.format(flat.shape))\n",
    "\n",
    "            latent = tf.contrib.layers.fully_connected(flat, self.n_latent, activation_fn=activation, scope='dcn{}/dense_{}'.format(self.label, 0))\n",
    "            print('net size: {}'.format(latent.shape))\n",
    "\n",
    "            inet = tf.contrib.layers.fully_connected(latent, int(flat.shape[-1]), activation_fn=activation, scope='dcn{}/dense_{}'.format(self.label, 1))\n",
    "            print('net size: {}'.format(inet.shape))\n",
    "            inet = tf.reshape(net, tf.shape(net), name='dcn{}/reshape_{}'.format(self.label, 0))\n",
    "            print('net size: {}'.format(inet.shape))\n",
    "\n",
    "            # Transposed convolutions\n",
    "            for r in range(self.n_layers):\n",
    "                inet = tf.contrib.layers.conv2d_transpose(inet, 3 if r == self.n_layers - 1 else n_filters, self.kernel, stride=2, \n",
    "                                                          activation_fn=last_activation if r == self.n_layers - 1 else activation,\n",
    "                                                          scope='dcn{}/tconv_{}'.format(self.label, r))\n",
    "                print('net size: {}'.format(inet.shape))\n",
    "                n_filters = n_filters // self.n_fscale\n",
    "\n",
    "            y = inet\n",
    "\n",
    "        with tf.name_scope('dcn{}_optimization'.format(self.label)):\n",
    "            lr = tf.placeholder(tf.float32, name='dcn_learning_rate')\n",
    "            loss = tf.nn.l2_loss(self.x - y)\n",
    "            adam = tf.train.AdamOptimizer(learning_rate=lr)\n",
    "            opt = adam.minimize(loss, var_list=self.parameters)\n",
    "            \n",
    "        return y, lr, loss, adam, opt, latent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create DCN instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "sess = tf.Session(graph=graph)\n",
    "\n",
    "dcn = AutoencoderDCN(sess, graph, patch_size=128, n_latent=512, n_layers=3, n_fscale=1, n_filters=16)\n",
    "\n",
    "print(dcn.summary())\n",
    "# print(dcn.count_parameters_breakdown())\n",
    "print('Compression stats:', dcn.compression_stats())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_x = data.next_training_batch(batch_id, training['batch_size'], 256)\n",
    "\n",
    "print(batch_x.shape)\n",
    "batch_t = np.zeros((batch_x.shape[0], 128, 128, 3), dtype=np.float32)\n",
    "\n",
    "for i in range(len(batch_x)):\n",
    "    batch_t[i] = resize(batch_x[i], [patch_size, patch_size], anti_aliasing=True)\n",
    "\n",
    "print(batch_t.shape)\n",
    "\n",
    "f = plotting.imsc(batch_x[0:8], ncols=8, figwidth=20)\n",
    "f = plotting.imsc(batch_t[0:8], ncols=8, figwidth=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcn.init()\n",
    "\n",
    "# Compute the number of available batches\n",
    "n_batches = data['training']['y'].shape[0] // training['batch_size']\n",
    "v_batches = data['validation']['y'].shape[0] // training['batch_size']\n",
    "\n",
    "loss = {'training': [], 'validation': []}\n",
    "loss_ma = deque(maxlen=n_batches)\n",
    "loss_va = deque(maxlen=v_batches)\n",
    "\n",
    "# Configure data augmentation\n",
    "augmentation_probs = {\n",
    "    'resize': 0.0,\n",
    "    'flip_h': 0.0,\n",
    "    'flip_v': 0.0\n",
    "}\n",
    "\n",
    "with tqdm.tqdm(total=training['n_epochs'], ncols=120, desc='Train') as pbar:\n",
    "\n",
    "    for epoch in range(0, training['n_epochs']):\n",
    "\n",
    "        # Iterate through batches of the training data \n",
    "        for batch_id in range(n_batches):\n",
    "            \n",
    "            # Pick random patch size - will be resized later for augmentation\n",
    "            current_patch = np.random.choice(np.arange(128, 256), 1) if np.random.uniform() < augmentation_probs['resize'] else patch_size\n",
    "            \n",
    "            # Sample next batch\n",
    "            batch_x = data.next_training_batch(batch_id, training['batch_size'], current_patch)\n",
    "            \n",
    "            # If rescaling needed, apply\n",
    "            if patch_size != current_patch:\n",
    "                batch_t = np.zeros((batch_x.shape[0], patch_size, patch_size, 3), dtype=np.float32)\n",
    "                for i in range(len(batch_x)):\n",
    "                    batch_t[i] = resize(batch_x[i], [patch_size, patch_size], anti_aliasing=True)\n",
    "                batch_x = batch_t                \n",
    "            \n",
    "            # Data augmentation - random horizontal flip\n",
    "            if np.random.uniform() < augmentation_probs['flip_h']: batch_x = batch_x[:, :, ::-1, :]\n",
    "            if np.random.uniform() < augmentation_probs['flip_v']: batch_x = batch_x[:, ::-1, :, :]\n",
    "            \n",
    "            # Make a training step\n",
    "            loss_value = dcn.training_step(batch_x, 1e-4)\n",
    "            loss_ma.append(loss_value)\n",
    "        \n",
    "        # Iterate through batches of the validation data\n",
    "        for batch_id in range(v_batches):\n",
    "            batch_x = data.next_validation_batch(batch_id, training['batch_size'])\n",
    "            batch_y = dcn.process(batch_x)\n",
    "            loss_value = np.linalg.norm(batch_x - batch_y)\n",
    "            loss_va.append(loss_value)\n",
    "\n",
    "        # Record average values for the whole epoch\n",
    "        loss['training'].append(np.mean(loss_ma))\n",
    "        loss['validation'].append(np.mean(loss_va))\n",
    "\n",
    "        # Update progress bar\n",
    "        pbar.set_postfix(loss=np.mean(loss['training']), loss_v=np.mean(loss['validation']))\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from helpers import utils\n",
    "\n",
    "fig = plt.figure(figsize=(20, 4))\n",
    "ax = fig.gca()\n",
    "ax.semilogy(utils.ma_conv(loss['training'], n=11))\n",
    "ax.semilogy(utils.ma_conv(loss['validation'], n=11))\n",
    "ax.semilogy(loss['training'], '.', alpha=0.3)\n",
    "ax.semilogy(loss['validation'], '.', alpha=0.3)\n",
    "ax.legend(['train', 'valid'], loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_id = (batch_id + 1) % n_batches\n",
    "batch_x = data.next_training_batch(batch_id, training['batch_size'], patch_size)\n",
    "fig = plotting.imsc(batch_x[:8], ncols=8, figwidth=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show a sample and a reconstruction of the current batch\n",
    "batch_y = dcn.process(batch_x)\n",
    "f = plotting.imsc(batch_x[0:8], ncols=8, figwidth=20)\n",
    "f = plotting.imsc(batch_y[0:8], ncols=8, figwidth=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import plotting\n",
    "\n",
    "# See latent distribution\n",
    "batch_z = dcn.compress(batch_x)\n",
    "batch_z = batch_z[:4]\n",
    "\n",
    "fig, axes = plotting.sub(len(batch_z), ncols=10, figwidth=20)\n",
    "\n",
    "for i, ax in enumerate(axes):\n",
    "    ax.hist(batch_z[i], bins=30)\n",
    "    ax.set_yticks([])\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
